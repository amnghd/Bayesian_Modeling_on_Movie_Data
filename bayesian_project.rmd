---
title: "Bayesian modeling and prediction for movies"
output:
  pdf_document: default
  html_document:
    fig_height: 4
    highlight: pygments
    theme: spacelab
---

## Setup

### Load packages

```{r load-packages, message = FALSE}
library(ggplot2)
library(dplyr)
library(statsr)
library(BAS)
library(GGally)
library(MASS)
```

### Load data


```{r load-data}
load("movies.Rdata")
```


* * *

## Part 1: Data


**Acquisition**: This data is randomly selected from IMDB and Rotten Tompato APIs from movies produced before 2016.

**Population**: To be included in this data set, the movie needs to be (1) in the Rotten Tomatoes and IMDB databases, (2) produced before 2016.

**Causality/Generalization**: Since the data is randomly sampled from the discussed population and no ***random assignment*** is performed, the resultSs of this study does not demonstrate any causality. Any results could be merely used to demonstrate correlation. The results is also only generalizable to the poplation discussed above, which are movies in IMDB and RT databases, produced before 2016.

* * *

## Part 2: Data manipulation (feature engineering)

We are going to engineer four variables to include into our models.

#### 2.1. Categorical ``feature_film`` with two levels (Yes,No)
```{r}
movies<- movies%>%mutate(feature_film = (title_type == 'Feature Film'))

movies$feature_film<-factor(movies$feature_film, labels = c('No', 'Yes'))
```

#### 2.2. Categorical ``drama`` with two levels (Yes,No)
```{r}
movies<- movies%>%mutate(drama = (genre == 'Drama'))

movies$drama<-factor(movies$drama, labels = c('No', 'Yes'))
```


#### 2.3. Categorical ``mpaa_rating_R`` with two levels (Yes,No)
```{r}
movies<- movies%>%mutate(mpaa_rating_R = (mpaa_rating == 'R'))

movies$mpaa_rating_R<-factor(movies$mpaa_rating_R, labels = c('No', 'Yes'))
```

#### 2.4. Categorical ``oscar_season`` with two levels (Yes,No)

For movies released in November, October, or December.
```{r}
movies<- movies%>%mutate(oscar_season = (thtr_rel_month %in% c(10,11,12)))

movies$oscar_season<-factor(movies$oscar_season, labels = c('No', 'Yes'))
```

#### 2.5. Categorical ``summer_season`` with two levels (Yes,No)

For movies released in May, June, July, or August
```{r}
movies<- movies%>%mutate(summer_season = (thtr_rel_month %in% c(5,6,7,8)))

movies$summer_season<-factor(movies$summer_season, labels = c('No', 'Yes'))
```
* * *

## Part 3: Exploratory data analysis

We will conduct a "exploratory data analysis of the relationship between ```audience_score``` and the new variables constructed in the previous part."

### 3.1. ``feature_film`` vs ``audience_score``

#### Visualized EDA
```{r}
ggplot(data=movies, aes(x=feature_film, y=audience_score))+
  geom_violin(trim = FALSE, draw_quantiles = c(0.25,0.5,0.75), show.legend = TRUE, color='black', fill='orange')
```

Our question here is whether being a feature fild can effect the audience score. he answer is yes. The median of the non-feature film audience score is even higher than the $0.75$ quantile of the feature film movies. We can see this also by summarizing the statistics.

#### Summary Statistics EDA

```{r}
movies%>%group_by(feature_film)%>%summarise(n = n(), median =median(audience_score), mean =mean(audience_score), std = sd(audience_score), SE = sd(audience_score)/sqrt(n()))
```
Shaping a $95\%$ confidence interval we can roughly say that $CI = \mu\pm2\times SE$. Therefore, we can see that $CI_{no}= 81\pm2*1.7=(78.3,82.7)$ and $CI_{yes}= 60.5\pm2*0.81=(59.9,62.1)$. We can confidently say that these two distributions are not from the same population. We can also perform a hypothesis test, which is not the focus of this section.


### 3.2. ``drama`` vs ``audience_score``

#### Visualized EDA
```{r}
ggplot(data=movies, aes(x=drama, y=audience_score))+
  geom_violin(trim = FALSE, draw_quantiles = c(0.25,0.5,0.75), show.legend = TRUE, color='black', fill='orange')
```
Although in general the drama movie tend to have higher audience score, more study is require to see if these two levels belong to different populations. We can double check that using the confidence interval.

#### Summary Statistics EDA

```{r}
movies%>%group_by(drama)%>%summarise(n = n(), median =median(audience_score), mean =mean(audience_score), std = sd(audience_score), SE = sd(audience_score)/sqrt(n()))
```
Shaping a $95\%$ confidence interval we can roughly say that $CI = \mu\pm2\times SE$. Therefore, we can see that $CI_{no}= 59.8\pm2\times 1.1=(57.6,62)$ and $CI_{yes}= 65.3\pm2*1.1=(63.1,67.5)$. We can see that the confidence intervals of these two populations are further apart from each other and we can be confident that there is a statistically significant difference here.



### 3.3. ``mpaa_rating_R`` vs ``audience_score``

#### Visualized EDA
```{r}
ggplot(data=movies, aes(x=mpaa_rating_R, y=audience_score))+
  geom_violin(trim = FALSE, draw_quantiles = c(0.25,0.5,0.75), show.legend = TRUE, color='black', fill='orange')
```
Graphically, it seems that there is no meaingful difference between the rater R movies and other movies. We can further investigate that using sthe summary statistics.

#### Summary Statistics EDA

```{r}
movies%>%group_by(mpaa_rating_R)%>%summarise(n = n(), median =median(audience_score), mean =mean(audience_score), std = sd(audience_score), SE = sd(audience_score)/sqrt(n()))
```
Shaping a $95\%$ confidence interval we can roughly say that $CI = \mu\pm2\times SE$. Therefore, we can see that $CI_{no}= 62.7\pm2\times 1.1=(60.5,64.9)$ and $CI_{yes}= 62.0\pm2\times1.1=(59.8,64.2)$. We can see that the confidence interval for the mean values of these two groups have a significant overlap. We can confidently say that no variance is explained by this feature.
* * *


### 3.4. ``oscar/-season`` vs ``audience_score``

#### Visualized EDA
```{r}
ggplot(data=movies, aes(x=oscar_season, y=audience_score))+
  geom_violin(trim = FALSE, draw_quantiles = c(0.25,0.5,0.75), show.legend = TRUE, color='black', fill='orange')
```
Graphically, it seems that there is a small difference between the ratings of movies in oscar season and other movies. We can further investigate that using sthe summary statistics.

#### Summary Statistics EDA

```{r}
movies%>%group_by(oscar_season)%>%summarise(n = n(), median =median(audience_score), mean =mean(audience_score), std = sd(audience_score), SE = sd(audience_score)/sqrt(n()))
```
Shaping a $95\%$ confidence interval we can roughly say that $CI = \mu\pm2\times SE$. Therefore, we can see that $CI_{no}= 61.8\pm2\times 0.9=(60,63.8)$ and $CI_{yes}= 63.7\pm2\times1.5=(60.7,66.7)$. We can see that the confidence interval for the mean values of these two groups have a significant overlap. We can confidently say that no variance is explained by this feature.

### 3.5. ``summer_season`` vs ``audience_score``

#### Visualized EDA
```{r}
ggplot(data=movies, aes(x=summer_season, y=audience_score))+
  geom_violin(trim = FALSE, draw_quantiles = c(0.25,0.5,0.75), show.legend = TRUE, color='black', fill='orange')
```
Graphically, it seems that there is a small difference between the ratings of movies in summer season and other movies. We can further investigate that using the summary statistics.

#### Summary Statistics EDA

```{r}
movies%>%group_by(summer_season)%>%summarise(n = n(), median =median(audience_score), mean =mean(audience_score), std = sd(audience_score), SE = sd(audience_score)/sqrt(n()))
```
Shaping a $95\%$ confidence interval we can roughly say that $CI = \mu\pm2\times SE$. Therefore, we can see that $CI_{no}= 62.6\pm2\times 1=(60.6,64.6)$ and $CI_{yes}= 61.8\pm2\times1.3=(59.2,64.4)$. We can see that the confidence interval for the mean values of these two groups have a significant overlap. We can confidently say that no variance is explained by this feature.

## Part 4: Modeling

We are going to "Develop a Bayesian regression model to predict audience_score from the following explanatory variables. Note that some of these variables are in the original dataset provided, and others are new variables  constructed earlier:"

-``feature_film``

-``drama``

-``runtime``

-``mpaa_rating_R``

-``thtr_rel_year``

-``oscar_season``

-``summer_season``

-``imdb_rating``

-``imdb_num_votes``

-``critics_score``

-``best_pic_nom``

-``best_pic_win``

-``best_actor_win``

-``best_actress_win``

-``best_dir_win``

-``top200_box``

First we are going to make a new dataframe that only contains these features.

```{r}
features_to_keep = c("feature_film","drama", "runtime", "mpaa_rating_R", "thtr_rel_year","oscar_season", "summer_season","imdb_rating", "imdb_num_votes","critics_score", "best_pic_win", "best_actor_win", "best_actress_win","best_dir_win", "top200_box", "audience_score")
new_movies <- movies%>%dplyr::select(one_of(features_to_keep))%>%na.omit()
```
Next we are going to generate the basic model that considers all of the mentioned features. Then, we need are going to make sure our model is accurate.

```{r}
m_movies_full <- lm(audience_score ~ ., data=new_movies)
summary(m_movies_full)
```
Looking at the frequentiest significance of features (p-value) we can conclude that many of the featuers are not significance. Instead of using frequentist adjusted -$R^2$, we are going to use the Bayesian BIC criterion for model selection. "BIC (Bayesian Information Criterion) is based on the model fit, while penalizing feature numbers" (similar to adjusted $R^2$". Let's calculate the BIC for the full model

```{r}
BIC (m_movies_full)
```
I will write a for loop to go through all the independent variables and output a variable that its drop will generate highest decrease in the BIC.

```{r}
ind_var = c("feature_film","drama", "runtime", "mpaa_rating_R", "thtr_rel_year","oscar_season", "summer_season","imdb_rating", "imdb_num_votes","critics_score", "best_pic_win", "best_actor_win", "best_actress_win","best_dir_win", "top200_box")

for (var in ind_var){
    formula = as.formula(paste("audience_score",paste(var), sep = " ~ . -"))
  model_arr = lm(formula, data = new_movies)
  print(c(var, BIC(model_arr)))
}
```
Our full model's BIC was 4931.9. Droping ```best_pic_win``` from the model results in $BIC= 4925.4$ which shows the highest increase in the model persimonioty.

Let's see if we can further decrease the BIC.

```{r}
ind_var_stp1 <- setdiff (ind_var, "best_pic_win")

for (var in ind_var_stp1){
    formula = as.formula(paste("audience_score",paste(var), sep = " ~ . -"))
  model_arr = lm(formula, data = new_movies)
  print(c(var, BIC(model_arr)))
}
```
As you might guess, this can be a quite crubsersome process. We actually performed similar frequentist analysis [here](https://github.com/amnghd/Movie_popularity_data_analysis/blob/master/reg_model_project.pdf). Instead of going into that details, R actualy has a function that performs a model selection backward by dropping faetures. The function is called stepAIC:

```{r}

model.lm<- lm(audience_score ~ ., data=new_movies)
model.bic <- stepAIC(model.lm,direction='both',k=log(nrow(new_movies)), trace=0) 
#k = log(n) is sometimes referred to as BIC or SBC

```

Looking at the trace from the final model, we see that the model with the best BIC is ``audience_score ~ runtime + imdb_rating + critics_score``. If you want to take a look at the trace of model selection, only assign ``TRUE`` to ``trace`` in the `stepAIC`` function.

```{r}
best_model <- lm (audience_score ~ runtime + imdb_rating + critics_score, data = new_movies)
```

This is one single model, which is better than others. However, it doesnt necessary capture all the available information. We might have to ensemble this model we other models using Bayesian Model Averaging, or BMA.

### 4.1. Bayesian Model Averaging
```{r}
bma_movies = bas.lm (audience_score ~ ., data=new_movies, prior = "BIC", modelprior =uniform())
#bma_movies
#summary(bma_movies)
```
The results can be quite detailed. It first mentios the posterior nclusion probablity of each feature. 
We can see that four features have the posterior probablity of not being zero more than 0.2. These are runtime, mpaa_ratin_R, imdb_rating, critics_score. 

Other than the variables, themselves, we need to also see which models have highest probablity. The results is shown in the summary of BMA computed aboce and is as follows:

mode| model formula | posterior probablity | R2 | BIC
----|---------------|----------------------|----|----
1|audience_score ~ runtime+imdb_rating+critics_score|0.149|3615.27
2|audience_score ~ imdb_rating + critics_score |0.148|3615.28
3|audience_score ~ imdb_rating + critics_score+best_actor_win |0.038 |3616.65
4|audience_score ~ mpaa_rating_R+imdb_rating+critics_score|0.37|3616.66
5|audience_score ~ runtime+mpaa_rating_R+imdb_rating+critistcs_score|0.0357|3616.71

As we also found using our BIC analysis, our first model is the best model. Notice that the posterior probablity is very low even for the best model. You should note that the model prior probablity for each model considering 15 variables (resulting in $2^{15}$ possibilities) is $p = 1/2^{15} =3*10^{-5}$. Therefore, reaching a posterior from such prior with only 650 records demonstrates that the model is reliable. 

We can also briefly take a look at the posterior probablity of the dominant features and $95\%$ credible interval for the coeffcients of the averaged model.

```{r}
coef_movie = coefficients(bma_movies)
par(mfrow = c(3,1))
plot(coef_movie, subset = c(9,4,11), ask=FALSE)

```
```{r}
confint(coef_movie)
```
From the figures we can see that the probablity of the coefficients being zero is extremely small. 

After reaching an acceptable model, it is now time to perform a model diagnostics. The summary table of the included variables shows that the following variables can be beneficial to be included in the model :``runtime, mpaa_rating_R, imdb_rating, critistcs_score, best_actor_win``. Nmerical variables need to be checked for normality and linearity to assure that the model is accurate.



### 4.2. Model Diagnostics

After reaching an acceptable model, it is now time to perform a model diagnostics. The summary table of the included variables shows that the following variables can be beneficial to be included in the model :``runtime, mpaa_rating_R, imdb_rating, critistcs_score, best_actor_win```. Nmerical variables need to be checked for normality and linearity to assure that the model is accurate.

#### 4.2.1. ```audience_score vs runtime```

**Linearity **

Let's check if ``audiece score`` is changing linearly with ``runtime``. We can check that by seeing how the residuals vary with the fitted value. If they show a random scatter around zero with equal variance, we can say that the data is normal. Let's look at the following figure.
```{r}
audience_runtime<-lm(data=new_movies, audience_score~runtime)
ggplot(data = audience_runtime, aes(x = .fitted, y = .resid)) +
  geom_point(color = 'chartreuse3') +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Fitted values") +
  ylab("Residuals")

```
We can see that the conditions for linearity doesn hold for this feature. Since this variable demonstrated a very high inclusion posterior probablity, we need to see if we can keep it. Let's try a couple of transformations. First let's try log.

```{r}
new_movies<- new_movies%>%mutate(log_runtime = log(runtime))

audience_logrun<-lm(data=new_movies, audience_score~log_runtime)
ggplot(data = audience_logrun, aes(x = .fitted, y = .resid)) +
  geom_point(color = 'darkgreen') +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Fitted values") +
  ylab("Residuals")

```
Although the result still demonstrates no complete linearity, we can see improvement. Let's continue to see if other conditions hold.

**Nearly Normal Residual**

First we check the histogram of the residuals:

```{r}
ggplot(data = audience_logrun, aes(x = .resid)) +
  geom_histogram(binwidth = 5, fill = 'chocolate1', color = 'black' ) +
  xlab("Residuals")
```
We can hardly say that the residuals are normally distributed around 0. Let's take a look at quantile-quantile (qq) plot.

```{r}
ggplot(data = audience_logrun, aes(sample = .resid)) +
  stat_qq(color = 'coral2')
```
```{r}
ggplot(new_movies, aes(x=log_runtime, y=audience_score))+geom_jitter(color='goldenrod4')+
  labs(x="runtime", y="IMDB Rating",
       title = 'Scatter Plot of IMDB Rating vs Runtime')+
  stat_smooth(method = "lm", se = TRUE)
```
The qq plot is also curved, which means it is not normal.



#### 4.2.2. ```audience_score vs imdb_rating```

**Linearity **

Let's check if ``audiece score`` is changing linearly with ``imdb_rating``. We can check that by seeing how the residuals vary with the fitted value. If they show a random scatter around zero with equal variance, we can say that the data is normal. Let's look at the following figure.
```{r}
audience_imdb<-lm(data=new_movies, audience_score~imdb_rating)
ggplot(data = audience_imdb, aes(x = .fitted, y = .resid)) +
  geom_point(color = 'chartreuse3') +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Fitted values") +
  ylab("Residuals")

```
We can see that the conditions for linearity doesn hold for this featurelog_audiencelog_audience. Since this variable demonstrated a very high inclusion posterior probablity, we need to see if we can keep it. Let's try a couple of transformations. First let's try log.

```{r}
new_movies<- new_movies%>%mutate(log_imdb = (imdb_rating)**3)

audience_imdbrun<-lm(data=new_movies, audience_score~log_imdb)
ggplot(data = audience_imdbrun, aes(x = .fitted, y = .resid)) +
  geom_point(color = 'darkgreen') +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Fitted values") +
  ylab("Residuals")

```
Although the results are a bit more linear, we still need to check the normality.

**Nearly Normal Residual**

First we check the histogram of the residuals:

```{r}
ggplot(data = audience_imdbrun, aes(x = .resid)) +
  geom_histogram(binwidth = .07, fill = 'chocolate1', color = 'black' ) +
  xlab("Residuals")
```
We can easily say that the residuals are normally distributed around 0. Let's take a look at quantile-quantile (qq) plot.

```{r}
ggplot(data = audience_imdbrun, aes(sample = .resid)) +
  stat_qq(color = 'coral2')
```
qqplot is also almost linear.We can say that data is linear.
```{r}
ggplot(new_movies, aes(x=(log_imdb), y=audience_score))+geom_jitter(color='goldenrod4')+
  labs(x="runtime", y="IMDB Rating",
       title = 'Scatter Plot of IMDB Rating vs Runtime')+
  stat_smooth(method = "lm", se = TRUE)
```
We can see that the new engineered feature ``imdb_log``` is linear and now its residuals are also normal.



#### 4.2.3. ```audience_score vs critics_score```

**Linearity **

Let's check if ``audiece score`` is changing linearly with ``critics_score``. We can check that by seeing how the residuals vary with the fitted value. If they show a random scatter around zero with equal variance, we can say that the data is normal. Let's look at the following figure.
```{r}
audience_critics<-lm(data=new_movies, audience_score~critics_score)
ggplot(data = audience_critics, aes(x = .fitted, y = .resid)) +
  geom_point(color = 'chartreuse3') +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Fitted values") +
  ylab("Residuals")

```
We can see that the conditions for linearity  hold for this feature. Its residual is scattered around 0 with constant variance.

**Nearly Normal Residual**

First we check the histogram of the residuals:

```{r}
ggplot(data = audience_critics, aes(x = .resid)) +
  geom_histogram(binwidth = 7, fill = 'chocolate1', color = 'black' ) +
  xlab("Residuals")
```
We can easily say that the residuals are normally distributed around 0. Let's take a look at quantile-quantile (qq) plot.

```{r}
ggplot(data = audience_critics, aes(sample = .resid)) +
  stat_qq(color = 'coral2')
```
```{r}
ggplot(new_movies, aes(x=critics_score, y=audience_score))+geom_jitter(color='goldenrod4')+
  labs(x="runtime", y="IMDB Rating",
       title = 'Scatter Plot of IMDB Rating vs Runtime')+
  stat_smooth(method = "lm", se = TRUE)
```

So we end up using these features from the main data set.

```{r}
final_dataset <-new_movies%>%dplyr::select( mpaa_rating_R, log_imdb, critics_score, best_actor_win, audience_score)
```




* * *

## Part 5: Prediction

Let's predict the audience score for the movie "Batman Begins".
```{r}
model_movies_final <- lm(audience_score ~ ., data =final_dataset)

new_movie <- data.frame(mpaa_rating_R = 'No', log_imdb=8.3**3, critics_score= 84, best_actor_win = 'no')

predict(model_movies_final, new_movie, interval = "prediction", level = 0.95)

#summary(model_movies_final)

```
The results of our prediction says that the ``audience_score`` lies between $83.2$ and $120.2$ for Batman Begins. 

The actual ``audience_score`` is 94% which lies within our predicted value. 

Let's see if we can do averaging preditcion.


```{r}
data.gprior =  bas.lm(audience_score ~ ., data=final_dataset, alpha=13, prior="g-prior")

new_movie <- data.frame(mpaa_rating_R = 'No', log_imdb=8.3**3, critics_score= 84, best_actor_win = 'no')

data.BMA = predict(data.gprior, newdata=new_movie, estimator="BMA", se.fit=TRUE, prediction=FALSE)

confint(data.BMA)


```
The prediction from BMA (Bayesian Model Averaging) is even more accurate. The credible interval for the audience score is $(78.9,120.0)$. Also, the predicted value is $98.8\%$. This is 4.5% higher than the actual value. 

* * *

## Part 6: Conclusion

In this work we performed a study on the movie data acquired from IMDB and Rotten Tomato APIs. The goal of the study was to predict the popularity of the movie (its IMDB rating) from the available data using Bayesian Modelling and Averaging. We performed a linear regression backward elimination to develop the model. We performed model selection and dropped features that do not match the crierion.  Finally, we developed a $95%$ credible interval for the prediction of Batman Begins. Our prediction was correct and the actual IMDB rating was inside the credible interval. Our proposed research questions demonstrated high capability.

,,